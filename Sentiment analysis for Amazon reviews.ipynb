{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf2e9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import html\n",
    "import time\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords as sw\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data set\n",
    "data =pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f122598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>pos_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "\n",
       "  pos_neg  \n",
       "0     pos  \n",
       "1     neg  \n",
       "2     pos  \n",
       "3     neg  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "641c2bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff9c6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column named 'pos_neg', which has value 'neg' if the overall rating is 1, 2 ,or 3, \n",
    "# and has value 'pos' of the overall rating is 4 or 5. \n",
    "data.loc[data.Score.isin([1,2,3]), 'pos_neg'] = 'neg'\n",
    "data.loc[data.Score.isin([4,5]), 'pos_neg'] = 'pos'\n",
    "df = data[['pos_neg', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f0bbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_neg</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos_neg                                               Text\n",
       "0     pos  I have bought several of the Vitality canned d...\n",
       "1     neg  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2     pos  This is a confection that has been around a fe...\n",
       "3     neg  If you are looking for the secret ingredient i...\n",
       "4     pos  Great taffy at a great price.  There was a wid..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3234275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_neg    0\n",
       "Text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whethere there is any missing data\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9537cc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c515016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    443777\n",
       "neg    124677\n",
       "Name: pos_neg, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the positive and negative reviews\n",
    "df.pos_neg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fedc4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample positive reveiws to get a balanced dataset\n",
    "neg = df.loc[df.pos_neg=='neg']\n",
    "pos = df.loc[df.pos_neg=='pos'].sample(n=df.pos_neg.value_counts()['neg'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c2ec4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "pos: 124677 , neg: 124677\n"
     ]
    }
   ],
   "source": [
    "print(type(pos))\n",
    "print(\"pos:\", len(pos), \", neg:\", len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe0461f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stopwords = sw.words('english')\n",
    "stopwords = stopwords + ['not_' + w for w in stopwords]\n",
    "\n",
    "# transform punctuation to blanks\n",
    "trans_punct = str.maketrans(string.punctuation,' '*len(string.punctuation)) \n",
    "\n",
    "# pad punctuation with blanks\n",
    "pad_punct = str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}) \n",
    "# remove \"_\" from string.punctuation\n",
    "invalidChars = str(string.punctuation.replace(\"_\", \"\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29f84122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line, ngram=1, neg_handling=True, remove_stop=False):\n",
    "    \"\"\"\n",
    "    Preprocessing the review texts\n",
    "    @params:\n",
    "        line                       - Required: the input text (Str)\n",
    "        ngram                  - Optional: number n in the n-gram model(Int, 1, 2, or 3)\n",
    "        neg_handling       - Optional: whether to perform negation handling (Boolean)\n",
    "        remove_stop        -Optional: whether to remove the stop words (Boolean)\n",
    "    \"\"\"\n",
    "        \n",
    "    line = html.unescape(str(line))\n",
    "    line = str(line).replace(\"can't\", \"can not\")\n",
    "    line = str(line).replace(\"n't\", \" not\")\n",
    "    \n",
    "    if neg_handling:\n",
    "        line = str(line).translate(pad_punct)  # If performing negation handling, pad punctuations with blanks\n",
    "        line = nltk.word_tokenize(line.lower()) # Word normalization and tokenization\n",
    "        tokens = []\n",
    "        negated = False\n",
    "        for t in line:\n",
    "            if t in ['not', 'no']:\n",
    "                negated = not negated\n",
    "            elif t in string.punctuation or not t.isalpha():\n",
    "                negated = False\n",
    "            else:\n",
    "                tokens.append('not_' + t if negated else t)  # add \"not_\" prefix to words behind \"not\", or \"no\"     \n",
    "    else:\n",
    "        line = str(line).translate(trans_punct)  # If not performing negation handling, remove punctuations\n",
    "        line = nltk.word_tokenize(line.lower()) # Word normalization and tokenization\n",
    "        tokens = line\n",
    "        \n",
    "        if ngram==2:\n",
    "         bi_tokens = list(nltk.bigrams(line))\n",
    "         bi_tokens = list(map('_'.join, bi_tokens))\n",
    "        bi_tokens = [i for i in bi_tokens if all(j not in invalidChars for j in i)]\n",
    "        tokens = tokens + bi_tokens\n",
    "\n",
    "    if ngram==3:\n",
    "        bi_tokens = list(nltk.bigrams(line))\n",
    "        bi_tokens = list(map('_'.join, bi_tokens))\n",
    "        bi_tokens = [i for i in bi_tokens if all(j not in invalidChars for j in i)]\n",
    "        tri_tokens = list(nltk.trigrams(line))\n",
    "        tri_tokens = list(map('_'.join, tri_tokens))\n",
    "        tri_tokens = [i for i in tri_tokens if all(j not in invalidChars for j in i)]\n",
    "        tokens = tokens + bi_tokens + tri_tokens    \n",
    "     \n",
    "    if remove_stop:\n",
    "        line = [lemmatizer.lemmatize(t) for t in tokens if t not in stopwords]\n",
    "    else:\n",
    "        line = [lemmatizer.lemmatize(t) for t in tokens] \n",
    "    \n",
    "    return ' '.join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c0d3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the positive reveiws\n",
    "pos_data = []\n",
    "n_pos = len(pos)\n",
    "for i, p in enumerate(pos['Text']):\n",
    "    pos_data.append(preprocessing(p, ngram=3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc67ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the negative reveiws\n",
    "neg_data = []\n",
    "n_neg = len(neg)\n",
    "for i, n in enumerate(neg['Text']):\n",
    "    neg_data.append(preprocessing(n, ngram=3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adeacbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the preprocessed data\n",
    "data = pos_data + neg_data\n",
    "labels = np.concatenate((pos['pos_neg'].values, neg['pos_neg'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35aac522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size =  149612 validation size =  49871 testing size =  49871\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to training, validation, test sets by 60-20-20\n",
    "train_data, rest_data, train_labels, rest_labels = train_test_split(data, labels, test_size=0.4, \n",
    "                                                                    stratify=labels, random_state=1234)\n",
    "valid_data, test_data, valid_labels, test_labels = train_test_split(rest_data, rest_labels, test_size=0.5, \n",
    "                                                                    stratify=rest_labels, random_state=1234)\n",
    "print(\"training size = \", len(train_data), \"validation size = \", len(valid_data), \"testing size = \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a98ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the frequencu of words\n",
    "# Push all tokens and compute the frequency of words\n",
    "tokens = [word for line in train_data for word in nltk.word_tokenize(line)]\n",
    "word_features = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13d8edc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 4173490 samples and 33080505 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2fc74bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 485414),\n",
       " ('i', 458634),\n",
       " ('a', 362638),\n",
       " ('and', 321562),\n",
       " ('it', 276055),\n",
       " ('to', 246623),\n",
       " ('of', 206679),\n",
       " ('is', 191803),\n",
       " ('br', 184557),\n",
       " ('this', 168636)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 10 most common words\n",
    "word_features.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9aa7d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477440"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features (words) which occur only once (This is to be used in the basic modeling process)\n",
    "topwords = [fpair[0] for fpair in list(word_features.most_common(len(word_features))) if fpair[1]>=2] \n",
    "len(topwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02c73374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1477353 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1477353 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "# Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "tf_vec = TfidfVectorizer()\n",
    "\n",
    "tf_vec.fit_transform([' '.join(topwords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5265fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training set\n",
    "# Vocabulary is from topwords\n",
    "train_features = tf_vec.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be50c757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149612, 1477353)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7919995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from test set\n",
    "test_features = tf_vec.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdabd1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49871, 1477353)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fec38cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic modelling\n",
    "#Naive Bayes model\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model\n",
    "# Train Model\n",
    "mnb_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "982af95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'neg' 'pos' ... 'neg' 'neg' 'pos']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "pred = mnb_model.predict(test_features)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b39e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8920214152513485\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = metrics.accuracy_score(test_labels, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3edf9712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.8709    0.9205    0.8950     24935\n",
      "         pos     0.9157    0.8636    0.8889     24936\n",
      "\n",
      "    accuracy                         0.8920     49871\n",
      "   macro avg     0.8933    0.8920    0.8919     49871\n",
      "weighted avg     0.8933    0.8920    0.8919     49871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=test_labels, y_pred=pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e437a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.89693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.8898    0.9061    0.8979     24935\n",
      "         pos     0.9044    0.8878    0.8960     24936\n",
      "\n",
      "    accuracy                         0.8969     49871\n",
      "   macro avg     0.8971    0.8969    0.8969     49871\n",
      "weighted avg     0.8971    0.8969    0.8969     49871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression \n",
    "lgr_model = LogisticRegression()\n",
    "print(lgr_model, end='\\n'*2)\n",
    "\n",
    "\n",
    "lgr_model.fit(train_features, train_labels)\n",
    "lgr_pred = lgr_model.predict(test_features)\n",
    "\n",
    "print('Accuracy = %.5f' % metrics.accuracy_score(test_labels, lgr_pred))\n",
    "print(metrics.classification_report(y_pred=lgr_pred, y_true=test_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35d42f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "\n",
      "Accuracy = 0.92254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg     0.9189    0.9269    0.9229     24935\n",
      "         pos     0.9263    0.9182    0.9222     24936\n",
      "\n",
      "    accuracy                         0.9225     49871\n",
      "   macro avg     0.9226    0.9225    0.9225     49871\n",
      "weighted avg     0.9226    0.9225    0.9225     49871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM : Linear Support Vector Model\n",
    "svc_model = LinearSVC()\n",
    "print(svc_model, end='\\n'*2)\n",
    "\n",
    "svc_model.fit(train_features, train_labels)\n",
    "svc_pred = svc_model.predict(test_features)\n",
    "\n",
    "print('Accuracy = %.5f' % metrics.accuracy_score(test_labels, svc_pred))\n",
    "print(metrics.classification_report(y_pred=svc_pred, y_true=test_labels, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
